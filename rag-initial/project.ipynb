{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d70ea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
      "     ---------------------------------------- 0.0/67.3 MB ? eta -:--:--\n",
      "     ------- ------------------------------- 13.6/67.3 MB 77.7 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 32.8/67.3 MB 83.2 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 53.0/67.3 MB 87.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  67.1/67.3 MB 88.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 67.3/67.3 MB 77.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp313-cp313-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (2.2.3)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-cpp-python) (3.1.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.2.1-cp313-cp313-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kenil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading faiss_cpu-1.10.0-cp313-cp313-win_amd64.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 13.7/13.7 MB 77.1 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 15.7/204.1 MB 79.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 34.9/204.1 MB 84.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 53.2/204.1 MB 86.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 73.4/204.1 MB 88.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 96.7/204.1 MB 91.9 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 115.6/204.1 MB 91.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 136.8/204.1 MB 92.6 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 157.8/204.1 MB 93.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 180.1/204.1 MB 94.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.1/204.1 MB 94.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 94.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 94.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 79.3 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 53.7 MB/s eta 0:00:00\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.4/10.4 MB 65.9 MB/s eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp313-cp313-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 60.4 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.1/11.1 MB 64.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 18.1/41.0 MB 91.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.0/41.0 MB 88.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 88.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 63.8 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 43.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 52.5 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 26.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp313-cp313-win_amd64.whl size=4882354 sha256=9f1e2963cc7ac52136c2ebb490a7b220fcffaa82d971fa59af41f5cb9763309e\n",
      "  Stored in directory: c:\\users\\kenil\\appdata\\local\\pip\\cache\\wheels\\50\\8d\\a7\\117fed2f4366af670c4d45dfb3fed01a85024c61b657457f28\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, Pillow, networkx, fsspec, filelock, faiss-cpu, diskcache, torch, scikit-learn, llama-cpp-python, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed Pillow-11.2.1 diskcache-5.6.3 faiss-cpu-1.10.0 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 llama-cpp-python-0.3.8 mpmath-1.3.0 networkx-3.4.2 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.0.2 sympy-1.13.1 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.6.0 transformers-4.51.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-cpp-python faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a0749b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0a7da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_init_from_model: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: Of course! Here are two quiz questions based on the context provided:\n",
      "1. What are the two types of worms recommended for composting in the Worm Factory 360?\n",
      "Answer: The two types of worms recommended for composting in the Worm Factory 360 are red wigglers (Eisenia fetida) and European (Belgian) Nightcrawlers (Eisenia hortensis).\n",
      "2. How many trays are needed to reach full operating capacity in the Worm Factory 360?\n",
      "Answer: According to the context, it takes 3 or more operating trays for the vermicomposter to be in full operation.\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "MODEL_PATH = \"llama-2-7b-chat.Q4_K_M.gguf\"\n",
    "DOC_PATH = \"document.txt\"\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_ctx=2048,\n",
    "    n_gpu_layers=32, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "with open(DOC_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "chunks = [full_text[i:i+500] for i in range(0, len(full_text), 500)]\n",
    "chunk_embeddings = embedder.encode(chunks)\n",
    "\n",
    "dimension = chunk_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(chunk_embeddings))\n",
    "chunk_map = {i: chunk for i, chunk in enumerate(chunks)}\n",
    "\n",
    "def retrieve(query, k=3):\n",
    "    query_embedding = embedder.encode([query])\n",
    "    _, I = index.search(np.array(query_embedding), k)\n",
    "    return [chunk_map[i] for i in I[0]]\n",
    "\n",
    "def generate_answer(context, question):\n",
    "    prompt = f\"\"\"Use the context below to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    output = llm(prompt, max_tokens=256, stop=[\"\\n\\n\"])\n",
    "    return output[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nAsk a question (or type 'exit'): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    context = \"\\n\\n\".join(retrieve(user_input))\n",
    "    answer = generate_answer(context, user_input)\n",
    "    print(f\"\\nAnswer: {answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
